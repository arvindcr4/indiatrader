# GPU-Accelerated Deployment

- [ ] Package inference code for serving models with FastAPI.
- [ ] Provide Dockerfile with CUDA support.
- [ ] Add examples for running inference locally and in the cloud.
