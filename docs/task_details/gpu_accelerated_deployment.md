# GPU-Accelerated Deployment

 - [x] Package inference code for serving models with FastAPI.
 - [x] Provide Dockerfile with CUDA support.
 - [x] Add examples for running inference locally and in the cloud.
